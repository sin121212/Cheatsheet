{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection\n",
    "\n",
    "1. Create database connector for pandas read_sql (IBM AS400, SQL Server)\n",
    "\n",
    "2. Read database table in chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turbodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQL_Server_Connection():\n",
    "    \n",
    "    cnxn = turbodbc.connect(DRIVER='ODBC Driver 17 for SQL Server',\n",
    "                            SERVER='',\n",
    "                            DATABASE='',\n",
    "                            UID='',\n",
    "                            PWD='')\n",
    "    \n",
    "    return cnxn\n",
    "\n",
    "# SQL_con = SQL_Server_Connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. IBM AS400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM AS400\n",
    "def Connector(__uid__,__pwd__):\n",
    "    \n",
    "    print('Create Database engine:')\n",
    "    \n",
    "    con = turbodbc.connect(\n",
    "        driver='{iSeries Access ODBC Driver}',\n",
    "        system='',\n",
    "        uid=__uid__,\n",
    "        pwd=__pwd__)\n",
    "                \n",
    "    # set autocommit here -> for make change in database\n",
    "    con.autocommit = True\n",
    "    print('autocommit mode:',con.autocommit)\n",
    "    \n",
    "    return con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data in Chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_df(query,eng,chunksize):\n",
    "    print(\"loading chunk data\")\n",
    "    \n",
    "    df_list = []  \n",
    "    # Create empty dataframe\n",
    "    concat_df = pd.DataFrame()\n",
    "    \n",
    "    i = 1\n",
    "    for chunk in pd.read_sql(query, eng, chunksize = chunksize):\n",
    "        print('loading row:',i*chunksize)\n",
    "        df_list.append(chunk)\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "    concat_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    print(concat_df.info())\n",
    "    \n",
    "    return concat_df\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def Import_abc_df(con,table_location):\n",
    "    \n",
    "    start_run_time = time()      \n",
    "    \n",
    "    q = \"SELECT * from table_name\"\n",
    "    \n",
    "    df = load_chunk_df(query=q, eng=con, chunksize=200000)\n",
    "    \n",
    "    time_taken = time() - start_run_time\n",
    "    \n",
    "    return df, time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
